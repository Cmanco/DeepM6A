Using Theano backend.
INFO (theano.gof.compilelock): Waiting for existing lock by process '104015' (I am process '105855')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/xsede/users/xs-tanfei/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-redhat-6.9-Santiago-x86_64-2.7.9-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '105855')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/xsede/users/xs-tanfei/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-redhat-6.9-Santiago-x86_64-2.7.9-64/lock_dir
Using gpu device 0: Tesla K80 (CNMeM is enabled with initial size: 10.0% of memory, cuDNN 5005)
loading data
3
(31415, 61, 4)
('train_label: count', (array([0, 1]), array([15707, 15708])))
('valid_label: count', (array([0, 1]), array([1959, 1960])))
('test_label: count', (array([0, 1]), array([1959, 1960])))
building model...............
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
cov1 (Convolution1D)             (None, 58, 80)        1360        convolution1d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 58, 80)        0           cov1[0][0]                       
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 58, 80)        0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
cov2 (Convolution1D)             (None, 57, 80)        12880       dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 57, 80)        0           cov2[0][0]                       
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 57, 80)        0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
cov3 (Convolution1D)             (None, 54, 80)        25680       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 54, 80)        0           cov3[0][0]                       
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 54, 80)        0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
cov4 (Convolution1D)             (None, 51, 80)        25680       dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 51, 80)        0           cov4[0][0]                       
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 51, 80)        0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
cov5 (Convolution1D)             (None, 48, 80)        25680       dropout_4[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 48, 80)        0           cov5[0][0]                       
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 48, 80)        0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 3840)          0           dropout_5[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 100)           384100      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_6 (LeakyReLU)          (None, 100)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_6 (Dropout)              (None, 100)           0           leakyrelu_6[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             101         dropout_6[0][0]                  
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 1)             0           dense_2[0][0]                    
====================================================================================================
Total params: 475481
____________________________________________________________________________________________________
compiling and fitting model...........
Train on 31415 samples, validate on 3919 samples
Epoch 1/500
Epoch 00000: val_loss improved from inf to 0.69314, saving model to ./bestmodel3.hdf5
6s - loss: 0.6932 - acc: 0.4957 - val_loss: 0.6931 - val_acc: 0.4999
Epoch 2/500
Epoch 00001: val_loss did not improve
3s - loss: 0.6932 - acc: 0.5033 - val_loss: 0.6932 - val_acc: 0.5001
Epoch 3/500
Epoch 00002: val_loss did not improve
3s - loss: 0.6933 - acc: 0.4952 - val_loss: 0.6931 - val_acc: 0.5001
Epoch 4/500
Epoch 00003: val_loss did not improve
3s - loss: 0.6932 - acc: 0.4951 - val_loss: 0.6931 - val_acc: 0.4999
Epoch 5/500
Epoch 00004: val_loss did not improve
3s - loss: 0.6932 - acc: 0.4954 - val_loss: 0.6931 - val_acc: 0.5001
Epoch 6/500
Epoch 00005: val_loss did not improve
3s - loss: 0.6932 - acc: 0.4944 - val_loss: 0.6932 - val_acc: 0.4999
Epoch 7/500
Epoch 00006: val_loss did not improve
3s - loss: 0.6932 - acc: 0.4996 - val_loss: 0.6931 - val_acc: 0.5001
Epoch 8/500
Epoch 00007: val_loss did not improve
3s - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6931 - val_acc: 0.5001
Epoch 9/500
Epoch 00008: val_loss did not improve
3s - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4999
Epoch 10/500
Epoch 00009: val_loss did not improve
3s - loss: 0.6932 - acc: 0.5009 - val_loss: 0.6932 - val_acc: 0.5001
Epoch 11/500
Epoch 00010: val_loss did not improve
3s - loss: 0.6932 - acc: 0.4997 - val_loss: 0.6931 - val_acc: 0.5001
Epoch 12/500
Epoch 00011: val_loss did not improve
3s - loss: 0.6931 - acc: 0.5040 - val_loss: 0.6932 - val_acc: 0.4999
Epoch 13/500
Epoch 00012: val_loss improved from 0.69314 to 0.69314, saving model to ./bestmodel3.hdf5
5s - loss: 0.6932 - acc: 0.5001 - val_loss: 0.6931 - val_acc: 0.5512
Epoch 14/500
Epoch 00013: val_loss improved from 0.69314 to 0.69313, saving model to ./bestmodel3.hdf5
4s - loss: 0.6932 - acc: 0.4964 - val_loss: 0.6931 - val_acc: 0.4999
Epoch 15/500
Epoch 00014: val_loss did not improve
3s - loss: 0.6932 - acc: 0.4963 - val_loss: 0.6931 - val_acc: 0.4999
Epoch 16/500
Epoch 00015: val_loss did not improve
3s - loss: 0.6932 - acc: 0.5016 - val_loss: 0.6931 - val_acc: 0.5001
Epoch 17/500
Epoch 00016: val_loss did not improve
3s - loss: 0.6932 - acc: 0.5042 - val_loss: 0.6932 - val_acc: 0.5001
Epoch 18/500
Epoch 00017: val_loss did not improve
3s - loss: 0.6932 - acc: 0.5017 - val_loss: 0.6932 - val_acc: 0.4999
Epoch 19/500
Epoch 00018: val_loss did not improve
3s - loss: 0.6932 - acc: 0.4990 - val_loss: 0.6932 - val_acc: 0.4999
Epoch 20/500
Epoch 00019: val_loss did not improve
3s - loss: 0.6932 - acc: 0.4992 - val_loss: 0.6931 - val_acc: 0.4999
Epoch 21/500
Epoch 00020: val_loss improved from 0.69313 to 0.69313, saving model to ./bestmodel3.hdf5
4s - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6931 - val_acc: 0.5001
Epoch 22/500
Epoch 00021: val_loss did not improve
3s - loss: 0.6931 - acc: 0.5043 - val_loss: 0.6931 - val_acc: 0.5001
Epoch 23/500
Epoch 00022: val_loss improved from 0.69313 to 0.69312, saving model to ./bestmodel3.hdf5
4s - loss: 0.6932 - acc: 0.5013 - val_loss: 0.6931 - val_acc: 0.4999
Epoch 24/500
Epoch 00023: val_loss did not improve
3s - loss: 0.6931 - acc: 0.5043 - val_loss: 0.6932 - val_acc: 0.4999
Epoch 25/500
Epoch 00024: val_loss improved from 0.69312 to 0.69311, saving model to ./bestmodel3.hdf5
4s - loss: 0.6932 - acc: 0.4968 - val_loss: 0.6931 - val_acc: 0.5001
Epoch 26/500
Epoch 00025: val_loss did not improve
3s - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6931 - val_acc: 0.4999
Epoch 27/500
Epoch 00026: val_loss improved from 0.69311 to 0.69308, saving model to ./bestmodel3.hdf5
4s - loss: 0.6931 - acc: 0.5016 - val_loss: 0.6931 - val_acc: 0.4999
Epoch 28/500
Epoch 00027: val_loss improved from 0.69308 to 0.69307, saving model to ./bestmodel3.hdf5
6s - loss: 0.6931 - acc: 0.5034 - val_loss: 0.6931 - val_acc: 0.5001
Epoch 29/500
Epoch 00028: val_loss did not improve
3s - loss: 0.6932 - acc: 0.4984 - val_loss: 0.6931 - val_acc: 0.5001
Epoch 30/500
Epoch 00029: val_loss improved from 0.69307 to 0.69304, saving model to ./bestmodel3.hdf5
3s - loss: 0.6931 - acc: 0.5029 - val_loss: 0.6930 - val_acc: 0.4999
Epoch 31/500
Epoch 00030: val_loss improved from 0.69304 to 0.69296, saving model to ./bestmodel3.hdf5
4s - loss: 0.6931 - acc: 0.5041 - val_loss: 0.6930 - val_acc: 0.5854
Epoch 32/500
Epoch 00031: val_loss improved from 0.69296 to 0.69288, saving model to ./bestmodel3.hdf5
3s - loss: 0.6930 - acc: 0.5096 - val_loss: 0.6929 - val_acc: 0.4999
Epoch 33/500
Epoch 00032: val_loss improved from 0.69288 to 0.69259, saving model to ./bestmodel3.hdf5
4s - loss: 0.6928 - acc: 0.5149 - val_loss: 0.6926 - val_acc: 0.6438
Epoch 34/500
Epoch 00033: val_loss improved from 0.69259 to 0.69177, saving model to ./bestmodel3.hdf5
3s - loss: 0.6923 - acc: 0.5319 - val_loss: 0.6918 - val_acc: 0.5001
Epoch 35/500
Epoch 00034: val_loss improved from 0.69177 to 0.68262, saving model to ./bestmodel3.hdf5
4s - loss: 0.6893 - acc: 0.5915 - val_loss: 0.6826 - val_acc: 0.6400
Epoch 36/500
Epoch 00035: val_loss improved from 0.68262 to 0.55886, saving model to ./bestmodel3.hdf5
3s - loss: 0.6212 - acc: 0.6972 - val_loss: 0.5589 - val_acc: 0.7155
Epoch 37/500
Epoch 00036: val_loss improved from 0.55886 to 0.52195, saving model to ./bestmodel3.hdf5
3s - loss: 0.5215 - acc: 0.7549 - val_loss: 0.5219 - val_acc: 0.7408
Epoch 38/500
Epoch 00037: val_loss improved from 0.52195 to 0.50363, saving model to ./bestmodel3.hdf5
4s - loss: 0.4841 - acc: 0.7792 - val_loss: 0.5036 - val_acc: 0.7650
Epoch 39/500
Epoch 00038: val_loss improved from 0.50363 to 0.48727, saving model to ./bestmodel3.hdf5
3s - loss: 0.4646 - acc: 0.7951 - val_loss: 0.4873 - val_acc: 0.7719
Epoch 40/500
Epoch 00039: val_loss improved from 0.48727 to 0.48620, saving model to ./bestmodel3.hdf5
3s - loss: 0.4472 - acc: 0.8047 - val_loss: 0.4862 - val_acc: 0.7744
Epoch 41/500
Epoch 00040: val_loss did not improve
3s - loss: 0.4318 - acc: 0.8124 - val_loss: 0.4956 - val_acc: 0.7716
Epoch 42/500
Epoch 00041: val_loss improved from 0.48620 to 0.45573, saving model to ./bestmodel3.hdf5
4s - loss: 0.4192 - acc: 0.8204 - val_loss: 0.4557 - val_acc: 0.7961
Epoch 43/500
Epoch 00042: val_loss did not improve
3s - loss: 0.4086 - acc: 0.8252 - val_loss: 0.4619 - val_acc: 0.7882
Epoch 44/500
Epoch 00043: val_loss did not improve
3s - loss: 0.3979 - acc: 0.8309 - val_loss: 0.4601 - val_acc: 0.7954
Epoch 45/500
Epoch 00044: val_loss improved from 0.45573 to 0.43957, saving model to ./bestmodel3.hdf5
4s - loss: 0.3935 - acc: 0.8343 - val_loss: 0.4396 - val_acc: 0.8035
Epoch 46/500
Epoch 00045: val_loss did not improve
3s - loss: 0.3914 - acc: 0.8355 - val_loss: 0.5020 - val_acc: 0.7747
Epoch 47/500
Epoch 00046: val_loss improved from 0.43957 to 0.43768, saving model to ./bestmodel3.hdf5
3s - loss: 0.3821 - acc: 0.8401 - val_loss: 0.4377 - val_acc: 0.8020
Epoch 48/500
Epoch 00047: val_loss improved from 0.43768 to 0.42906, saving model to ./bestmodel3.hdf5
3s - loss: 0.3791 - acc: 0.8420 - val_loss: 0.4291 - val_acc: 0.8058
Epoch 49/500
Epoch 00048: val_loss did not improve
3s - loss: 0.3744 - acc: 0.8433 - val_loss: 0.4380 - val_acc: 0.8040
Epoch 50/500
Epoch 00049: val_loss did not improve
3s - loss: 0.3732 - acc: 0.8463 - val_loss: 0.4303 - val_acc: 0.8063
Epoch 51/500
Epoch 00050: val_loss improved from 0.42906 to 0.42615, saving model to ./bestmodel3.hdf5
4s - loss: 0.3659 - acc: 0.8494 - val_loss: 0.4261 - val_acc: 0.8125
Epoch 52/500
Epoch 00051: val_loss improved from 0.42615 to 0.41787, saving model to ./bestmodel3.hdf5
3s - loss: 0.3638 - acc: 0.8493 - val_loss: 0.4179 - val_acc: 0.8127
Epoch 53/500
Epoch 00052: val_loss did not improve
3s - loss: 0.3578 - acc: 0.8529 - val_loss: 0.4255 - val_acc: 0.8109
Epoch 54/500
Epoch 00053: val_loss improved from 0.41787 to 0.41104, saving model to ./bestmodel3.hdf5
3s - loss: 0.3483 - acc: 0.8588 - val_loss: 0.4110 - val_acc: 0.8234
Epoch 55/500
Epoch 00054: val_loss improved from 0.41104 to 0.41080, saving model to ./bestmodel3.hdf5
4s - loss: 0.3475 - acc: 0.8604 - val_loss: 0.4108 - val_acc: 0.8199
Epoch 56/500
Epoch 00055: val_loss improved from 0.41080 to 0.40683, saving model to ./bestmodel3.hdf5
3s - loss: 0.3456 - acc: 0.8583 - val_loss: 0.4068 - val_acc: 0.8237
Epoch 57/500
Epoch 00056: val_loss improved from 0.40683 to 0.40403, saving model to ./bestmodel3.hdf5
4s - loss: 0.3416 - acc: 0.8608 - val_loss: 0.4040 - val_acc: 0.8275
Epoch 58/500
Epoch 00057: val_loss improved from 0.40403 to 0.39867, saving model to ./bestmodel3.hdf5
3s - loss: 0.3353 - acc: 0.8659 - val_loss: 0.3987 - val_acc: 0.8290
Epoch 59/500
Epoch 00058: val_loss did not improve
3s - loss: 0.3336 - acc: 0.8635 - val_loss: 0.4010 - val_acc: 0.8324
Epoch 60/500
Epoch 00059: val_loss improved from 0.39867 to 0.38780, saving model to ./bestmodel3.hdf5
3s - loss: 0.3311 - acc: 0.8661 - val_loss: 0.3878 - val_acc: 0.8316
Epoch 61/500
Epoch 00060: val_loss did not improve
3s - loss: 0.3283 - acc: 0.8676 - val_loss: 0.3965 - val_acc: 0.8331
Epoch 62/500
Epoch 00061: val_loss improved from 0.38780 to 0.38189, saving model to ./bestmodel3.hdf5
4s - loss: 0.3252 - acc: 0.8689 - val_loss: 0.3819 - val_acc: 0.8347
Epoch 63/500
Epoch 00062: val_loss did not improve
3s - loss: 0.3213 - acc: 0.8716 - val_loss: 0.3977 - val_acc: 0.8349
Epoch 64/500
Epoch 00063: val_loss did not improve
3s - loss: 0.3207 - acc: 0.8709 - val_loss: 0.3876 - val_acc: 0.8403
Epoch 65/500
Epoch 00064: val_loss did not improve
3s - loss: 0.3166 - acc: 0.8733 - val_loss: 0.3837 - val_acc: 0.8438
Epoch 66/500
Epoch 00065: val_loss improved from 0.38189 to 0.37593, saving model to ./bestmodel3.hdf5
4s - loss: 0.3132 - acc: 0.8760 - val_loss: 0.3759 - val_acc: 0.8431
Epoch 67/500
Epoch 00066: val_loss improved from 0.37593 to 0.36951, saving model to ./bestmodel3.hdf5
3s - loss: 0.3101 - acc: 0.8768 - val_loss: 0.3695 - val_acc: 0.8446
Epoch 68/500
Epoch 00067: val_loss improved from 0.36951 to 0.36801, saving model to ./bestmodel3.hdf5
5s - loss: 0.3059 - acc: 0.8796 - val_loss: 0.3680 - val_acc: 0.8464
Epoch 69/500
Epoch 00068: val_loss did not improve
3s - loss: 0.3044 - acc: 0.8791 - val_loss: 0.3701 - val_acc: 0.8464
Epoch 70/500
Epoch 00069: val_loss improved from 0.36801 to 0.36445, saving model to ./bestmodel3.hdf5
3s - loss: 0.3005 - acc: 0.8816 - val_loss: 0.3644 - val_acc: 0.8482
Epoch 71/500
Epoch 00070: val_loss improved from 0.36445 to 0.36223, saving model to ./bestmodel3.hdf5
4s - loss: 0.2974 - acc: 0.8831 - val_loss: 0.3622 - val_acc: 0.8497
Epoch 72/500
Epoch 00071: val_loss did not improve
3s - loss: 0.2977 - acc: 0.8835 - val_loss: 0.3707 - val_acc: 0.8484
Epoch 73/500
Epoch 00072: val_loss did not improve
3s - loss: 0.2906 - acc: 0.8867 - val_loss: 0.3666 - val_acc: 0.8500
Epoch 74/500
Epoch 00073: val_loss improved from 0.36223 to 0.35932, saving model to ./bestmodel3.hdf5
4s - loss: 0.2893 - acc: 0.8858 - val_loss: 0.3593 - val_acc: 0.8523
Epoch 75/500
Epoch 00074: val_loss did not improve
3s - loss: 0.2882 - acc: 0.8876 - val_loss: 0.3612 - val_acc: 0.8574
Epoch 76/500
Epoch 00075: val_loss improved from 0.35932 to 0.35733, saving model to ./bestmodel3.hdf5
4s - loss: 0.2836 - acc: 0.8894 - val_loss: 0.3573 - val_acc: 0.8581
Epoch 77/500
Epoch 00076: val_loss did not improve
3s - loss: 0.2800 - acc: 0.8921 - val_loss: 0.3621 - val_acc: 0.8569
Epoch 78/500
Epoch 00077: val_loss did not improve
3s - loss: 0.2803 - acc: 0.8917 - val_loss: 0.3587 - val_acc: 0.8574
Epoch 79/500
Epoch 00078: val_loss improved from 0.35733 to 0.35518, saving model to ./bestmodel3.hdf5
3s - loss: 0.2792 - acc: 0.8902 - val_loss: 0.3552 - val_acc: 0.8556
Epoch 80/500
Epoch 00079: val_loss did not improve
3s - loss: 0.2764 - acc: 0.8927 - val_loss: 0.3567 - val_acc: 0.8617
Epoch 81/500
Epoch 00080: val_loss improved from 0.35518 to 0.34590, saving model to ./bestmodel3.hdf5
4s - loss: 0.2751 - acc: 0.8937 - val_loss: 0.3459 - val_acc: 0.8576
Epoch 82/500
Epoch 00081: val_loss did not improve
3s - loss: 0.2751 - acc: 0.8931 - val_loss: 0.3542 - val_acc: 0.8607
Epoch 83/500
Epoch 00082: val_loss did not improve
3s - loss: 0.2726 - acc: 0.8950 - val_loss: 0.3602 - val_acc: 0.8556
Epoch 84/500
Epoch 00083: val_loss did not improve
3s - loss: 0.2727 - acc: 0.8938 - val_loss: 0.3477 - val_acc: 0.8614
Epoch 85/500
Epoch 00084: val_loss did not improve
3s - loss: 0.2720 - acc: 0.8948 - val_loss: 0.3577 - val_acc: 0.8609
Epoch 86/500
Epoch 00085: val_loss did not improve
3s - loss: 0.2729 - acc: 0.8936 - val_loss: 0.3638 - val_acc: 0.8507
Epoch 87/500
Epoch 00086: val_loss improved from 0.34590 to 0.34538, saving model to ./bestmodel3.hdf5
4s - loss: 0.2706 - acc: 0.8951 - val_loss: 0.3454 - val_acc: 0.8635
Epoch 88/500
Epoch 00087: val_loss did not improve
3s - loss: 0.2658 - acc: 0.8983 - val_loss: 0.3585 - val_acc: 0.8599
Epoch 89/500
Epoch 00088: val_loss improved from 0.34538 to 0.34022, saving model to ./bestmodel3.hdf5
4s - loss: 0.2663 - acc: 0.8972 - val_loss: 0.3402 - val_acc: 0.8609
Epoch 90/500
Epoch 00089: val_loss did not improve
3s - loss: 0.2669 - acc: 0.8961 - val_loss: 0.3512 - val_acc: 0.8640
Epoch 91/500
Epoch 00090: val_loss did not improve
3s - loss: 0.2631 - acc: 0.8976 - val_loss: 0.3421 - val_acc: 0.8620
Epoch 92/500
Epoch 00091: val_loss did not improve
3s - loss: 0.2639 - acc: 0.8978 - val_loss: 0.3482 - val_acc: 0.8637
Epoch 93/500
Epoch 00092: val_loss improved from 0.34022 to 0.33837, saving model to ./bestmodel3.hdf5
4s - loss: 0.2648 - acc: 0.8972 - val_loss: 0.3384 - val_acc: 0.8625
Epoch 94/500
Epoch 00093: val_loss did not improve
3s - loss: 0.2629 - acc: 0.8965 - val_loss: 0.3499 - val_acc: 0.8655
Epoch 95/500
Epoch 00094: val_loss did not improve
3s - loss: 0.2629 - acc: 0.8987 - val_loss: 0.3469 - val_acc: 0.8635
Epoch 96/500
Epoch 00095: val_loss did not improve
3s - loss: 0.2627 - acc: 0.8975 - val_loss: 0.3490 - val_acc: 0.8625
Epoch 97/500
Epoch 00096: val_loss did not improve
3s - loss: 0.2620 - acc: 0.8985 - val_loss: 0.3440 - val_acc: 0.8653
Epoch 98/500
Epoch 00097: val_loss did not improve
3s - loss: 0.2585 - acc: 0.9015 - val_loss: 0.3464 - val_acc: 0.8637
Epoch 99/500
Epoch 00098: val_loss did not improve
3s - loss: 0.2586 - acc: 0.8983 - val_loss: 0.3474 - val_acc: 0.8627
Epoch 100/500
Epoch 00099: val_loss did not improve
3s - loss: 0.2579 - acc: 0.9012 - val_loss: 0.3400 - val_acc: 0.8660
Epoch 101/500
Epoch 00100: val_loss did not improve
3s - loss: 0.2568 - acc: 0.8998 - val_loss: 0.3490 - val_acc: 0.8640
Epoch 102/500
Epoch 00101: val_loss did not improve
3s - loss: 0.2544 - acc: 0.9024 - val_loss: 0.3396 - val_acc: 0.8660
Epoch 103/500
Epoch 00102: val_loss did not improve
3s - loss: 0.2563 - acc: 0.9009 - val_loss: 0.3465 - val_acc: 0.8643
Epoch 104/500
Epoch 00103: val_loss did not improve
3s - loss: 0.2564 - acc: 0.9019 - val_loss: 0.3528 - val_acc: 0.8650
Epoch 105/500
Epoch 00104: val_loss did not improve
3s - loss: 0.2537 - acc: 0.9010 - val_loss: 0.3431 - val_acc: 0.8658
Epoch 106/500
Epoch 00105: val_loss did not improve
3s - loss: 0.2546 - acc: 0.9014 - val_loss: 0.3573 - val_acc: 0.8589
Epoch 107/500
Epoch 00106: val_loss did not improve
3s - loss: 0.2557 - acc: 0.8997 - val_loss: 0.3525 - val_acc: 0.8625
Epoch 108/500
Epoch 00107: val_loss did not improve
3s - loss: 0.2498 - acc: 0.9042 - val_loss: 0.3497 - val_acc: 0.8597
Epoch 109/500
Epoch 00108: val_loss did not improve
3s - loss: 0.2515 - acc: 0.9023 - val_loss: 0.3500 - val_acc: 0.8627
Epoch 110/500
Epoch 00109: val_loss did not improve
3s - loss: 0.2530 - acc: 0.9028 - val_loss: 0.3478 - val_acc: 0.8627
Epoch 111/500
Epoch 00110: val_loss did not improve
3s - loss: 0.2503 - acc: 0.9034 - val_loss: 0.3471 - val_acc: 0.8632
Epoch 112/500
Epoch 00111: val_loss did not improve
3s - loss: 0.2512 - acc: 0.9026 - val_loss: 0.3401 - val_acc: 0.8678
Epoch 113/500
Epoch 00112: val_loss improved from 0.33837 to 0.33620, saving model to ./bestmodel3.hdf5
3s - loss: 0.2505 - acc: 0.9042 - val_loss: 0.3362 - val_acc: 0.8683
Epoch 114/500
Epoch 00113: val_loss did not improve
3s - loss: 0.2480 - acc: 0.9043 - val_loss: 0.3449 - val_acc: 0.8668
Epoch 115/500
Epoch 00114: val_loss did not improve
3s - loss: 0.2491 - acc: 0.9050 - val_loss: 0.3457 - val_acc: 0.8632
Epoch 116/500
Epoch 00115: val_loss did not improve
3s - loss: 0.2450 - acc: 0.9049 - val_loss: 0.3451 - val_acc: 0.8678
Epoch 117/500
Epoch 00116: val_loss did not improve
3s - loss: 0.2488 - acc: 0.9038 - val_loss: 0.3470 - val_acc: 0.8632
Epoch 118/500
Epoch 00117: val_loss did not improve
3s - loss: 0.2490 - acc: 0.9047 - val_loss: 0.3387 - val_acc: 0.8653
Epoch 119/500
Epoch 00118: val_loss did not improve
3s - loss: 0.2493 - acc: 0.9041 - val_loss: 0.3424 - val_acc: 0.8658
Epoch 120/500
Epoch 00119: val_loss did not improve
3s - loss: 0.2471 - acc: 0.9053 - val_loss: 0.3521 - val_acc: 0.8676
Epoch 121/500
Epoch 00120: val_loss did not improve
3s - loss: 0.2474 - acc: 0.9051 - val_loss: 0.3443 - val_acc: 0.8643
Epoch 122/500
Epoch 00121: val_loss did not improve
3s - loss: 0.2469 - acc: 0.9040 - val_loss: 0.3462 - val_acc: 0.8660
Epoch 123/500
Epoch 00122: val_loss improved from 0.33620 to 0.33259, saving model to ./bestmodel3.hdf5
4s - loss: 0.2447 - acc: 0.9049 - val_loss: 0.3326 - val_acc: 0.8704
Epoch 124/500
Epoch 00123: val_loss did not improve
3s - loss: 0.2452 - acc: 0.9063 - val_loss: 0.3510 - val_acc: 0.8635
Epoch 125/500
Epoch 00124: val_loss did not improve
3s - loss: 0.2444 - acc: 0.9058 - val_loss: 0.3493 - val_acc: 0.8620
Epoch 126/500
Epoch 00125: val_loss did not improve
3s - loss: 0.2441 - acc: 0.9055 - val_loss: 0.3462 - val_acc: 0.8660
Epoch 127/500
Epoch 00126: val_loss did not improve
3s - loss: 0.2433 - acc: 0.9067 - val_loss: 0.3413 - val_acc: 0.8681
Epoch 128/500
Epoch 00127: val_loss did not improve
3s - loss: 0.2426 - acc: 0.9064 - val_loss: 0.3483 - val_acc: 0.8643
Epoch 129/500
Epoch 00128: val_loss did not improve
3s - loss: 0.2415 - acc: 0.9073 - val_loss: 0.3450 - val_acc: 0.8655
Epoch 130/500
Epoch 00129: val_loss did not improve
3s - loss: 0.2418 - acc: 0.9058 - val_loss: 0.3350 - val_acc: 0.8681
Epoch 131/500
Epoch 00130: val_loss did not improve
3s - loss: 0.2433 - acc: 0.9050 - val_loss: 0.3376 - val_acc: 0.8671
Epoch 132/500
Epoch 00131: val_loss did not improve
3s - loss: 0.2389 - acc: 0.9076 - val_loss: 0.3709 - val_acc: 0.8614
Epoch 133/500
Epoch 00132: val_loss did not improve
3s - loss: 0.2400 - acc: 0.9083 - val_loss: 0.3394 - val_acc: 0.8681
Epoch 134/500
Epoch 00133: val_loss did not improve
3s - loss: 0.2406 - acc: 0.9077 - val_loss: 0.3346 - val_acc: 0.8683
Epoch 135/500
Epoch 00134: val_loss did not improve
3s - loss: 0.2411 - acc: 0.9062 - val_loss: 0.3435 - val_acc: 0.8663
Epoch 136/500
Epoch 00135: val_loss did not improve
3s - loss: 0.2400 - acc: 0.9076 - val_loss: 0.3429 - val_acc: 0.8658
Epoch 137/500
Epoch 00136: val_loss did not improve
3s - loss: 0.2395 - acc: 0.9077 - val_loss: 0.3440 - val_acc: 0.8650
Epoch 138/500
Epoch 00137: val_loss did not improve
3s - loss: 0.2383 - acc: 0.9075 - val_loss: 0.3360 - val_acc: 0.8691
Epoch 139/500
Epoch 00138: val_loss did not improve
3s - loss: 0.2385 - acc: 0.9078 - val_loss: 0.3370 - val_acc: 0.8665
Epoch 140/500
Epoch 00139: val_loss did not improve
3s - loss: 0.2365 - acc: 0.9088 - val_loss: 0.3379 - val_acc: 0.8671
Epoch 141/500
Epoch 00140: val_loss did not improve
3s - loss: 0.2393 - acc: 0.9077 - val_loss: 0.3367 - val_acc: 0.8665
Epoch 142/500
Epoch 00141: val_loss did not improve
3s - loss: 0.2367 - acc: 0.9086 - val_loss: 0.3448 - val_acc: 0.8694
Epoch 143/500
Epoch 00142: val_loss did not improve
3s - loss: 0.2379 - acc: 0.9094 - val_loss: 0.3336 - val_acc: 0.8686
Epoch 144/500
Epoch 00143: val_loss did not improve
3s - loss: 0.2366 - acc: 0.9086 - val_loss: 0.3360 - val_acc: 0.8714
Epoch 145/500
Epoch 00144: val_loss did not improve
3s - loss: 0.2338 - acc: 0.9125 - val_loss: 0.3412 - val_acc: 0.8648
Epoch 146/500
Epoch 00145: val_loss did not improve
3s - loss: 0.2331 - acc: 0.9110 - val_loss: 0.3391 - val_acc: 0.8691
Epoch 147/500
Epoch 00146: val_loss did not improve
3s - loss: 0.2352 - acc: 0.9092 - val_loss: 0.3355 - val_acc: 0.8696
Epoch 148/500
Epoch 00147: val_loss did not improve
3s - loss: 0.2363 - acc: 0.9100 - val_loss: 0.3371 - val_acc: 0.8671
Epoch 149/500
Epoch 00148: val_loss did not improve
3s - loss: 0.2311 - acc: 0.9110 - val_loss: 0.3340 - val_acc: 0.8671
Epoch 150/500
Epoch 00149: val_loss improved from 0.33259 to 0.33097, saving model to ./bestmodel3.hdf5
4s - loss: 0.2335 - acc: 0.9103 - val_loss: 0.3310 - val_acc: 0.8699
Epoch 151/500
Epoch 00150: val_loss did not improve
3s - loss: 0.2331 - acc: 0.9105 - val_loss: 0.3485 - val_acc: 0.8671
Epoch 152/500
Epoch 00151: val_loss did not improve
3s - loss: 0.2321 - acc: 0.9110 - val_loss: 0.3536 - val_acc: 0.8681
Epoch 153/500
Epoch 00152: val_loss did not improve
3s - loss: 0.2334 - acc: 0.9106 - val_loss: 0.3365 - val_acc: 0.8699
Epoch 154/500
Epoch 00153: val_loss did not improve
3s - loss: 0.2327 - acc: 0.9106 - val_loss: 0.3367 - val_acc: 0.8734
Epoch 155/500
Epoch 00154: val_loss did not improve
3s - loss: 0.2329 - acc: 0.9109 - val_loss: 0.3346 - val_acc: 0.8704
Epoch 156/500
Epoch 00155: val_loss did not improve
3s - loss: 0.2312 - acc: 0.9106 - val_loss: 0.3355 - val_acc: 0.8701
Epoch 157/500
Epoch 00156: val_loss did not improve
3s - loss: 0.2325 - acc: 0.9108 - val_loss: 0.3351 - val_acc: 0.8686
Epoch 158/500
Epoch 00157: val_loss did not improve
3s - loss: 0.2304 - acc: 0.9114 - val_loss: 0.3382 - val_acc: 0.8676
Epoch 159/500
Epoch 00158: val_loss did not improve
3s - loss: 0.2327 - acc: 0.9118 - val_loss: 0.3404 - val_acc: 0.8714
Epoch 160/500
Epoch 00159: val_loss did not improve
3s - loss: 0.2293 - acc: 0.9126 - val_loss: 0.3404 - val_acc: 0.8686
Epoch 161/500
Epoch 00160: val_loss did not improve
3s - loss: 0.2307 - acc: 0.9120 - val_loss: 0.3391 - val_acc: 0.8711
Epoch 162/500
Epoch 00161: val_loss did not improve
3s - loss: 0.2281 - acc: 0.9140 - val_loss: 0.3436 - val_acc: 0.8742
Epoch 163/500
Epoch 00162: val_loss did not improve
3s - loss: 0.2302 - acc: 0.9102 - val_loss: 0.3368 - val_acc: 0.8691
Epoch 164/500
Epoch 00163: val_loss did not improve
3s - loss: 0.2275 - acc: 0.9124 - val_loss: 0.3372 - val_acc: 0.8717
Epoch 165/500
Epoch 00164: val_loss did not improve
3s - loss: 0.2279 - acc: 0.9132 - val_loss: 0.3429 - val_acc: 0.8701
Epoch 166/500
Epoch 00165: val_loss improved from 0.33097 to 0.32890, saving model to ./bestmodel3.hdf5
4s - loss: 0.2263 - acc: 0.9122 - val_loss: 0.3289 - val_acc: 0.8714
Epoch 167/500
Epoch 00166: val_loss did not improve
3s - loss: 0.2261 - acc: 0.9135 - val_loss: 0.3393 - val_acc: 0.8709
Epoch 168/500
Epoch 00167: val_loss did not improve
3s - loss: 0.2247 - acc: 0.9130 - val_loss: 0.3439 - val_acc: 0.8729
Epoch 169/500
Epoch 00168: val_loss did not improve
3s - loss: 0.2282 - acc: 0.9133 - val_loss: 0.3451 - val_acc: 0.8699
Epoch 170/500
Epoch 00169: val_loss did not improve
3s - loss: 0.2254 - acc: 0.9148 - val_loss: 0.3396 - val_acc: 0.8734
Epoch 171/500
Epoch 00170: val_loss did not improve
3s - loss: 0.2269 - acc: 0.9132 - val_loss: 0.3439 - val_acc: 0.8694
Epoch 172/500
Epoch 00171: val_loss did not improve
3s - loss: 0.2255 - acc: 0.9144 - val_loss: 0.3361 - val_acc: 0.8717
Epoch 173/500
Epoch 00172: val_loss did not improve
3s - loss: 0.2270 - acc: 0.9132 - val_loss: 0.3385 - val_acc: 0.8745
Epoch 174/500
Epoch 00173: val_loss did not improve
3s - loss: 0.2260 - acc: 0.9131 - val_loss: 0.3362 - val_acc: 0.8714
Epoch 175/500
Epoch 00174: val_loss did not improve
3s - loss: 0.2212 - acc: 0.9157 - val_loss: 0.3691 - val_acc: 0.8650
Epoch 176/500
Epoch 00175: val_loss improved from 0.32890 to 0.32864, saving model to ./bestmodel3.hdf5
4s - loss: 0.2253 - acc: 0.9134 - val_loss: 0.3286 - val_acc: 0.8709
Epoch 177/500
Epoch 00176: val_loss did not improve
3s - loss: 0.2235 - acc: 0.9137 - val_loss: 0.3387 - val_acc: 0.8722
Epoch 178/500
Epoch 00177: val_loss did not improve
3s - loss: 0.2229 - acc: 0.9161 - val_loss: 0.3291 - val_acc: 0.8745
Epoch 179/500
Epoch 00178: val_loss did not improve
3s - loss: 0.2201 - acc: 0.9170 - val_loss: 0.3341 - val_acc: 0.8711
Epoch 180/500
Epoch 00179: val_loss did not improve
3s - loss: 0.2230 - acc: 0.9141 - val_loss: 0.3470 - val_acc: 0.8724
Epoch 181/500
Epoch 00180: val_loss improved from 0.32864 to 0.32804, saving model to ./bestmodel3.hdf5
3s - loss: 0.2235 - acc: 0.9150 - val_loss: 0.3280 - val_acc: 0.8711
Epoch 182/500
Epoch 00181: val_loss did not improve
3s - loss: 0.2225 - acc: 0.9147 - val_loss: 0.3352 - val_acc: 0.8709
Epoch 183/500
Epoch 00182: val_loss did not improve
3s - loss: 0.2230 - acc: 0.9160 - val_loss: 0.3446 - val_acc: 0.8704
Epoch 184/500
Epoch 00183: val_loss did not improve
3s - loss: 0.2213 - acc: 0.9168 - val_loss: 0.3287 - val_acc: 0.8729
Epoch 185/500
Epoch 00184: val_loss did not improve
3s - loss: 0.2216 - acc: 0.9153 - val_loss: 0.3318 - val_acc: 0.8714
Epoch 186/500
Epoch 00185: val_loss did not improve
3s - loss: 0.2209 - acc: 0.9173 - val_loss: 0.3318 - val_acc: 0.8732
Epoch 187/500
Epoch 00186: val_loss did not improve
3s - loss: 0.2175 - acc: 0.9165 - val_loss: 0.3309 - val_acc: 0.8719
Epoch 188/500
Epoch 00187: val_loss did not improve
3s - loss: 0.2203 - acc: 0.9163 - val_loss: 0.3389 - val_acc: 0.8722
Epoch 189/500
Epoch 00188: val_loss did not improve
3s - loss: 0.2159 - acc: 0.9171 - val_loss: 0.3346 - val_acc: 0.8722
Epoch 190/500
Epoch 00189: val_loss did not improve
3s - loss: 0.2172 - acc: 0.9169 - val_loss: 0.3421 - val_acc: 0.8706
Epoch 191/500
Epoch 00190: val_loss did not improve
3s - loss: 0.2166 - acc: 0.9171 - val_loss: 0.3363 - val_acc: 0.8732
Epoch 192/500
Epoch 00191: val_loss did not improve
3s - loss: 0.2180 - acc: 0.9154 - val_loss: 0.3334 - val_acc: 0.8750
Epoch 193/500
Epoch 00192: val_loss did not improve
3s - loss: 0.2149 - acc: 0.9173 - val_loss: 0.3346 - val_acc: 0.8717
Epoch 194/500
Epoch 00193: val_loss did not improve
3s - loss: 0.2148 - acc: 0.9172 - val_loss: 0.3426 - val_acc: 0.8704
Epoch 195/500
Epoch 00194: val_loss did not improve
3s - loss: 0.2160 - acc: 0.9172 - val_loss: 0.3367 - val_acc: 0.8729
Epoch 196/500
Epoch 00195: val_loss did not improve
3s - loss: 0.2141 - acc: 0.9191 - val_loss: 0.3400 - val_acc: 0.8750
Epoch 197/500
Epoch 00196: val_loss did not improve
3s - loss: 0.2150 - acc: 0.9178 - val_loss: 0.3414 - val_acc: 0.8719
Epoch 198/500
Epoch 00197: val_loss did not improve
3s - loss: 0.2164 - acc: 0.9160 - val_loss: 0.3439 - val_acc: 0.8729
Epoch 199/500
Epoch 00198: val_loss improved from 0.32804 to 0.32606, saving model to ./bestmodel3.hdf5
4s - loss: 0.2144 - acc: 0.9174 - val_loss: 0.3261 - val_acc: 0.8732
Epoch 200/500
Epoch 00199: val_loss did not improve
3s - loss: 0.2139 - acc: 0.9183 - val_loss: 0.3286 - val_acc: 0.8729
Epoch 201/500
Epoch 00200: val_loss did not improve
3s - loss: 0.2135 - acc: 0.9184 - val_loss: 0.3316 - val_acc: 0.8745
Epoch 202/500
Epoch 00201: val_loss did not improve
3s - loss: 0.2146 - acc: 0.9193 - val_loss: 0.3394 - val_acc: 0.8714
Epoch 203/500
Epoch 00202: val_loss did not improve
3s - loss: 0.2140 - acc: 0.9163 - val_loss: 0.3399 - val_acc: 0.8762
Epoch 204/500
Epoch 00203: val_loss did not improve
3s - loss: 0.2127 - acc: 0.9190 - val_loss: 0.3343 - val_acc: 0.8755
Epoch 205/500
Epoch 00204: val_loss did not improve
3s - loss: 0.2139 - acc: 0.9173 - val_loss: 0.3293 - val_acc: 0.8732
Epoch 206/500
Epoch 00205: val_loss did not improve
3s - loss: 0.2126 - acc: 0.9182 - val_loss: 0.3373 - val_acc: 0.8729
Epoch 207/500
Epoch 00206: val_loss did not improve
3s - loss: 0.2104 - acc: 0.9205 - val_loss: 0.3377 - val_acc: 0.8734
Epoch 208/500
Epoch 00207: val_loss did not improve
3s - loss: 0.2123 - acc: 0.9191 - val_loss: 0.3379 - val_acc: 0.8747
Epoch 209/500
Epoch 00208: val_loss did not improve
3s - loss: 0.2107 - acc: 0.9197 - val_loss: 0.3325 - val_acc: 0.8724
Epoch 210/500
Epoch 00209: val_loss did not improve
3s - loss: 0.2111 - acc: 0.9195 - val_loss: 0.3282 - val_acc: 0.8732
Epoch 211/500
Epoch 00210: val_loss did not improve
3s - loss: 0.2086 - acc: 0.9199 - val_loss: 0.3506 - val_acc: 0.8724
Epoch 212/500
Epoch 00211: val_loss did not improve
3s - loss: 0.2080 - acc: 0.9193 - val_loss: 0.3366 - val_acc: 0.8747
Epoch 213/500
Epoch 00212: val_loss did not improve
3s - loss: 0.2082 - acc: 0.9197 - val_loss: 0.3292 - val_acc: 0.8729
Epoch 214/500
Epoch 00213: val_loss did not improve
3s - loss: 0.2074 - acc: 0.9219 - val_loss: 0.3292 - val_acc: 0.8739
Epoch 215/500
Epoch 00214: val_loss did not improve
3s - loss: 0.2113 - acc: 0.9203 - val_loss: 0.3321 - val_acc: 0.8757
Epoch 216/500
Epoch 00215: val_loss did not improve
3s - loss: 0.2130 - acc: 0.9188 - val_loss: 0.3420 - val_acc: 0.8722
Epoch 217/500
Epoch 00216: val_loss did not improve
3s - loss: 0.2095 - acc: 0.9206 - val_loss: 0.3299 - val_acc: 0.8739
Epoch 218/500
Epoch 00217: val_loss did not improve
3s - loss: 0.2057 - acc: 0.9217 - val_loss: 0.3313 - val_acc: 0.8750
Epoch 219/500
Epoch 00218: val_loss did not improve
3s - loss: 0.2062 - acc: 0.9213 - val_loss: 0.3348 - val_acc: 0.8757
Epoch 220/500
Epoch 00219: val_loss did not improve
3s - loss: 0.2088 - acc: 0.9194 - val_loss: 0.3303 - val_acc: 0.8768
Epoch 221/500
Epoch 00220: val_loss did not improve
3s - loss: 0.2071 - acc: 0.9201 - val_loss: 0.3298 - val_acc: 0.8757
Epoch 222/500
Epoch 00221: val_loss did not improve
3s - loss: 0.2082 - acc: 0.9195 - val_loss: 0.3284 - val_acc: 0.8765
Epoch 223/500
Epoch 00222: val_loss did not improve
3s - loss: 0.2059 - acc: 0.9213 - val_loss: 0.3323 - val_acc: 0.8762
Epoch 224/500
Epoch 00223: val_loss did not improve
3s - loss: 0.2066 - acc: 0.9215 - val_loss: 0.3294 - val_acc: 0.8742
Epoch 225/500
Epoch 00224: val_loss did not improve
3s - loss: 0.2057 - acc: 0.9220 - val_loss: 0.3346 - val_acc: 0.8775
Epoch 226/500
Epoch 00225: val_loss did not improve
3s - loss: 0.2072 - acc: 0.9208 - val_loss: 0.3332 - val_acc: 0.8750
Epoch 227/500
Epoch 00226: val_loss did not improve
3s - loss: 0.2048 - acc: 0.9206 - val_loss: 0.3302 - val_acc: 0.8742
Epoch 228/500
Epoch 00227: val_loss did not improve
3s - loss: 0.2051 - acc: 0.9223 - val_loss: 0.3271 - val_acc: 0.8768
Epoch 229/500
Epoch 00228: val_loss did not improve
3s - loss: 0.2041 - acc: 0.9205 - val_loss: 0.3376 - val_acc: 0.8727
Epoch 230/500
Epoch 00229: val_loss did not improve
3s - loss: 0.2054 - acc: 0.9202 - val_loss: 0.3374 - val_acc: 0.8734
Epoch 231/500
Epoch 00230: val_loss did not improve
3s - loss: 0.2040 - acc: 0.9214 - val_loss: 0.3343 - val_acc: 0.8739
Epoch 232/500
Epoch 00231: val_loss did not improve
3s - loss: 0.2055 - acc: 0.9212 - val_loss: 0.3270 - val_acc: 0.8752
Epoch 233/500
Epoch 00232: val_loss did not improve
3s - loss: 0.2017 - acc: 0.9233 - val_loss: 0.3329 - val_acc: 0.8739
Epoch 234/500
Epoch 00233: val_loss did not improve
3s - loss: 0.2031 - acc: 0.9239 - val_loss: 0.3290 - val_acc: 0.8742
Epoch 235/500
Epoch 00234: val_loss did not improve
3s - loss: 0.2024 - acc: 0.9222 - val_loss: 0.3271 - val_acc: 0.8765
Epoch 236/500
Epoch 00235: val_loss did not improve
3s - loss: 0.2025 - acc: 0.9221 - val_loss: 0.3342 - val_acc: 0.8734
Epoch 237/500
Epoch 00236: val_loss did not improve
3s - loss: 0.2046 - acc: 0.9222 - val_loss: 0.3264 - val_acc: 0.8719
Epoch 238/500
Epoch 00237: val_loss did not improve
3s - loss: 0.2018 - acc: 0.9244 - val_loss: 0.3267 - val_acc: 0.8762
Epoch 239/500
Epoch 00238: val_loss did not improve
3s - loss: 0.2005 - acc: 0.9231 - val_loss: 0.3344 - val_acc: 0.8750
Epoch 240/500
Epoch 00239: val_loss improved from 0.32606 to 0.32571, saving model to ./bestmodel3.hdf5
4s - loss: 0.2006 - acc: 0.9217 - val_loss: 0.3257 - val_acc: 0.8762
Epoch 241/500
Epoch 00240: val_loss did not improve
3s - loss: 0.2010 - acc: 0.9238 - val_loss: 0.3277 - val_acc: 0.8719
Epoch 242/500
Epoch 00241: val_loss did not improve
3s - loss: 0.1996 - acc: 0.9235 - val_loss: 0.3303 - val_acc: 0.8739
Epoch 243/500
Epoch 00242: val_loss did not improve
3s - loss: 0.1974 - acc: 0.9245 - val_loss: 0.3363 - val_acc: 0.8770
Epoch 244/500
Epoch 00243: val_loss did not improve
3s - loss: 0.1984 - acc: 0.9217 - val_loss: 0.3260 - val_acc: 0.8765
Epoch 245/500
Epoch 00244: val_loss did not improve
3s - loss: 0.1968 - acc: 0.9244 - val_loss: 0.3316 - val_acc: 0.8783
Epoch 246/500
Epoch 00245: val_loss did not improve
3s - loss: 0.1969 - acc: 0.9254 - val_loss: 0.3484 - val_acc: 0.8760
Epoch 247/500
Epoch 00246: val_loss did not improve
3s - loss: 0.2012 - acc: 0.9246 - val_loss: 0.3282 - val_acc: 0.8752
Epoch 248/500
Epoch 00247: val_loss did not improve
3s - loss: 0.1976 - acc: 0.9243 - val_loss: 0.3439 - val_acc: 0.8737
Epoch 249/500
Epoch 00248: val_loss did not improve
3s - loss: 0.1941 - acc: 0.9257 - val_loss: 0.3277 - val_acc: 0.8739
Epoch 250/500
Epoch 00249: val_loss did not improve
3s - loss: 0.1971 - acc: 0.9255 - val_loss: 0.3439 - val_acc: 0.8717
Epoch 251/500
Epoch 00250: val_loss did not improve
3s - loss: 0.1972 - acc: 0.9238 - val_loss: 0.3303 - val_acc: 0.8742
Epoch 252/500
Epoch 00251: val_loss did not improve
3s - loss: 0.1945 - acc: 0.9258 - val_loss: 0.3326 - val_acc: 0.8765
Epoch 253/500
Epoch 00252: val_loss improved from 0.32571 to 0.32411, saving model to ./bestmodel3.hdf5
3s - loss: 0.1966 - acc: 0.9245 - val_loss: 0.3241 - val_acc: 0.8737
Epoch 254/500
Epoch 00253: val_loss improved from 0.32411 to 0.32089, saving model to ./bestmodel3.hdf5
3s - loss: 0.1952 - acc: 0.9259 - val_loss: 0.3209 - val_acc: 0.8765
Epoch 255/500
Epoch 00254: val_loss did not improve
3s - loss: 0.1939 - acc: 0.9269 - val_loss: 0.3334 - val_acc: 0.8755
Epoch 256/500
Epoch 00255: val_loss did not improve
3s - loss: 0.1951 - acc: 0.9260 - val_loss: 0.3320 - val_acc: 0.8765
Epoch 257/500
Epoch 00256: val_loss did not improve
3s - loss: 0.1932 - acc: 0.9265 - val_loss: 0.3260 - val_acc: 0.8788
Epoch 258/500
Epoch 00257: val_loss did not improve
3s - loss: 0.1947 - acc: 0.9249 - val_loss: 0.3358 - val_acc: 0.8739
Epoch 259/500
Epoch 00258: val_loss did not improve
3s - loss: 0.1955 - acc: 0.9260 - val_loss: 0.3243 - val_acc: 0.8806
Epoch 260/500
Epoch 00259: val_loss did not improve
3s - loss: 0.1962 - acc: 0.9234 - val_loss: 0.3449 - val_acc: 0.8734
Epoch 261/500
Epoch 00260: val_loss did not improve
3s - loss: 0.1936 - acc: 0.9263 - val_loss: 0.3371 - val_acc: 0.8765
Epoch 262/500
Epoch 00261: val_loss did not improve
3s - loss: 0.1912 - acc: 0.9270 - val_loss: 0.3280 - val_acc: 0.8760
Epoch 263/500
Epoch 00262: val_loss did not improve
3s - loss: 0.1930 - acc: 0.9264 - val_loss: 0.3307 - val_acc: 0.8791
Epoch 264/500
Epoch 00263: val_loss did not improve
3s - loss: 0.1898 - acc: 0.9276 - val_loss: 0.3355 - val_acc: 0.8762
Epoch 265/500
Epoch 00264: val_loss did not improve
3s - loss: 0.1926 - acc: 0.9253 - val_loss: 0.3276 - val_acc: 0.8780
Epoch 266/500
Epoch 00265: val_loss did not improve
3s - loss: 0.1901 - acc: 0.9261 - val_loss: 0.3307 - val_acc: 0.8793
Epoch 267/500
Epoch 00266: val_loss did not improve
3s - loss: 0.1936 - acc: 0.9255 - val_loss: 0.3272 - val_acc: 0.8737
Epoch 268/500
Epoch 00267: val_loss did not improve
3s - loss: 0.1930 - acc: 0.9260 - val_loss: 0.3326 - val_acc: 0.8737
Epoch 269/500
Epoch 00268: val_loss did not improve
3s - loss: 0.1888 - acc: 0.9277 - val_loss: 0.3367 - val_acc: 0.8816
Epoch 270/500
Epoch 00269: val_loss did not improve
3s - loss: 0.1890 - acc: 0.9286 - val_loss: 0.3256 - val_acc: 0.8773
Epoch 271/500
Epoch 00270: val_loss did not improve
3s - loss: 0.1898 - acc: 0.9289 - val_loss: 0.3310 - val_acc: 0.8796
Epoch 272/500
Epoch 00271: val_loss did not improve
3s - loss: 0.1881 - acc: 0.9283 - val_loss: 0.3238 - val_acc: 0.8806
Epoch 273/500
Epoch 00272: val_loss did not improve
3s - loss: 0.1883 - acc: 0.9275 - val_loss: 0.3326 - val_acc: 0.8816
Epoch 274/500
Epoch 00273: val_loss improved from 0.32089 to 0.31964, saving model to ./bestmodel3.hdf5
5s - loss: 0.1896 - acc: 0.9272 - val_loss: 0.3196 - val_acc: 0.8785
Epoch 275/500
Epoch 00274: val_loss did not improve
3s - loss: 0.1902 - acc: 0.9276 - val_loss: 0.3395 - val_acc: 0.8765
Epoch 276/500
Epoch 00275: val_loss did not improve
3s - loss: 0.1873 - acc: 0.9279 - val_loss: 0.3379 - val_acc: 0.8752
Epoch 277/500
Epoch 00276: val_loss did not improve
3s - loss: 0.1864 - acc: 0.9283 - val_loss: 0.3339 - val_acc: 0.8785
Epoch 278/500
Epoch 00277: val_loss did not improve
3s - loss: 0.1847 - acc: 0.9277 - val_loss: 0.3350 - val_acc: 0.8816
Epoch 279/500
Epoch 00278: val_loss did not improve
3s - loss: 0.1876 - acc: 0.9292 - val_loss: 0.3277 - val_acc: 0.8824
Epoch 280/500
Epoch 00279: val_loss did not improve
3s - loss: 0.1871 - acc: 0.9294 - val_loss: 0.3272 - val_acc: 0.8796
Epoch 281/500
Epoch 00280: val_loss did not improve
3s - loss: 0.1868 - acc: 0.9277 - val_loss: 0.3311 - val_acc: 0.8793
Epoch 282/500
Epoch 00281: val_loss did not improve
3s - loss: 0.1877 - acc: 0.9275 - val_loss: 0.3221 - val_acc: 0.8780
Epoch 283/500
Epoch 00282: val_loss did not improve
3s - loss: 0.1882 - acc: 0.9275 - val_loss: 0.3239 - val_acc: 0.8775
Epoch 284/500
Epoch 00283: val_loss did not improve
3s - loss: 0.1863 - acc: 0.9283 - val_loss: 0.3219 - val_acc: 0.8798
Epoch 285/500
Epoch 00284: val_loss did not improve
3s - loss: 0.1848 - acc: 0.9289 - val_loss: 0.3462 - val_acc: 0.8752
Epoch 286/500
Epoch 00285: val_loss did not improve
3s - loss: 0.1838 - acc: 0.9292 - val_loss: 0.3297 - val_acc: 0.8788
Epoch 287/500
Epoch 00286: val_loss did not improve
3s - loss: 0.1865 - acc: 0.9289 - val_loss: 0.3306 - val_acc: 0.8791
Epoch 288/500
Epoch 00287: val_loss did not improve
3s - loss: 0.1848 - acc: 0.9297 - val_loss: 0.3243 - val_acc: 0.8775
Epoch 289/500
Epoch 00288: val_loss did not improve
3s - loss: 0.1819 - acc: 0.9304 - val_loss: 0.3356 - val_acc: 0.8739
Epoch 290/500
Epoch 00289: val_loss did not improve
3s - loss: 0.1845 - acc: 0.9301 - val_loss: 0.3276 - val_acc: 0.8793
Epoch 291/500
Epoch 00290: val_loss did not improve
3s - loss: 0.1827 - acc: 0.9302 - val_loss: 0.3281 - val_acc: 0.8780
Epoch 292/500
Epoch 00291: val_loss did not improve
3s - loss: 0.1792 - acc: 0.9311 - val_loss: 0.3399 - val_acc: 0.8788
Epoch 293/500
Epoch 00292: val_loss did not improve
3s - loss: 0.1849 - acc: 0.9294 - val_loss: 0.3356 - val_acc: 0.8760
Epoch 294/500
Epoch 00293: val_loss did not improve
3s - loss: 0.1809 - acc: 0.9308 - val_loss: 0.3288 - val_acc: 0.8811
Epoch 295/500
Epoch 00294: val_loss did not improve
3s - loss: 0.1806 - acc: 0.9301 - val_loss: 0.3358 - val_acc: 0.8819
Epoch 296/500
Epoch 00295: val_loss did not improve
3s - loss: 0.1798 - acc: 0.9322 - val_loss: 0.3310 - val_acc: 0.8788
Epoch 297/500
Epoch 00296: val_loss did not improve
3s - loss: 0.1806 - acc: 0.9306 - val_loss: 0.3376 - val_acc: 0.8765
Epoch 298/500
Epoch 00297: val_loss did not improve
3s - loss: 0.1767 - acc: 0.9313 - val_loss: 0.3396 - val_acc: 0.8752
Epoch 299/500
Epoch 00298: val_loss did not improve
3s - loss: 0.1802 - acc: 0.9295 - val_loss: 0.3306 - val_acc: 0.8839
Epoch 300/500
Epoch 00299: val_loss did not improve
3s - loss: 0.1797 - acc: 0.9310 - val_loss: 0.3290 - val_acc: 0.8803
Epoch 301/500
Epoch 00300: val_loss did not improve
3s - loss: 0.1776 - acc: 0.9335 - val_loss: 0.3343 - val_acc: 0.8803
Epoch 302/500
Epoch 00301: val_loss did not improve
3s - loss: 0.1806 - acc: 0.9290 - val_loss: 0.3316 - val_acc: 0.8788
Epoch 303/500
Epoch 00302: val_loss did not improve
3s - loss: 0.1788 - acc: 0.9317 - val_loss: 0.3298 - val_acc: 0.8852
Epoch 304/500
Epoch 00303: val_loss did not improve
3s - loss: 0.1776 - acc: 0.9316 - val_loss: 0.3298 - val_acc: 0.8806
Epoch 305/500
Epoch 00304: val_loss did not improve
3s - loss: 0.1785 - acc: 0.9304 - val_loss: 0.3342 - val_acc: 0.8778
Epoch 306/500
Epoch 00305: val_loss did not improve
3s - loss: 0.1797 - acc: 0.9305 - val_loss: 0.3299 - val_acc: 0.8785
Epoch 307/500
Epoch 00306: val_loss did not improve
3s - loss: 0.1783 - acc: 0.9308 - val_loss: 0.3281 - val_acc: 0.8839
Epoch 308/500
Epoch 00307: val_loss did not improve
3s - loss: 0.1763 - acc: 0.9315 - val_loss: 0.3305 - val_acc: 0.8816
Epoch 309/500
Epoch 00308: val_loss did not improve
3s - loss: 0.1764 - acc: 0.9325 - val_loss: 0.3416 - val_acc: 0.8765
Epoch 310/500
Epoch 00309: val_loss did not improve
3s - loss: 0.1759 - acc: 0.9328 - val_loss: 0.3356 - val_acc: 0.8801
Epoch 311/500
Epoch 00310: val_loss did not improve
3s - loss: 0.1775 - acc: 0.9319 - val_loss: 0.3299 - val_acc: 0.8808
Epoch 312/500
Epoch 00311: val_loss did not improve
3s - loss: 0.1768 - acc: 0.9320 - val_loss: 0.3264 - val_acc: 0.8796
Epoch 313/500
Epoch 00312: val_loss did not improve
3s - loss: 0.1762 - acc: 0.9329 - val_loss: 0.3375 - val_acc: 0.8768
Epoch 314/500
Epoch 00313: val_loss did not improve
3s - loss: 0.1750 - acc: 0.9326 - val_loss: 0.3274 - val_acc: 0.8803
Epoch 315/500
Epoch 00314: val_loss did not improve
3s - loss: 0.1724 - acc: 0.9334 - val_loss: 0.3401 - val_acc: 0.8798
Epoch 316/500
Epoch 00315: val_loss did not improve
3s - loss: 0.1724 - acc: 0.9344 - val_loss: 0.3459 - val_acc: 0.8778
Epoch 317/500
Epoch 00316: val_loss did not improve
3s - loss: 0.1736 - acc: 0.9338 - val_loss: 0.3414 - val_acc: 0.8778
Epoch 318/500
Epoch 00317: val_loss did not improve
3s - loss: 0.1749 - acc: 0.9319 - val_loss: 0.3318 - val_acc: 0.8801
Epoch 319/500
Epoch 00318: val_loss did not improve
3s - loss: 0.1741 - acc: 0.9331 - val_loss: 0.3358 - val_acc: 0.8788
Epoch 320/500
Epoch 00319: val_loss did not improve
3s - loss: 0.1729 - acc: 0.9332 - val_loss: 0.3339 - val_acc: 0.8773
Epoch 321/500
Epoch 00320: val_loss did not improve
3s - loss: 0.1726 - acc: 0.9328 - val_loss: 0.3384 - val_acc: 0.8791
Epoch 322/500
Epoch 00321: val_loss did not improve
3s - loss: 0.1731 - acc: 0.9331 - val_loss: 0.3402 - val_acc: 0.8813
Epoch 323/500
Epoch 00322: val_loss did not improve
3s - loss: 0.1707 - acc: 0.9349 - val_loss: 0.3389 - val_acc: 0.8778
Epoch 324/500
Epoch 00323: val_loss did not improve
3s - loss: 0.1697 - acc: 0.9351 - val_loss: 0.3418 - val_acc: 0.8813
Epoch 325/500
Epoch 00324: val_loss did not improve
Epoch 00324: early stopping
3s - loss: 0.1690 - acc: 0.9349 - val_loss: 0.3349 - val_acc: 0.8834
training done!
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
cov1 (Convolution1D)             (None, 58, 80)        1360        convolution1d_input_2[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 58, 80)        0           cov1[0][0]                       
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 58, 80)        0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
cov2 (Convolution1D)             (None, 57, 80)        12880       dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 57, 80)        0           cov2[0][0]                       
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 57, 80)        0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
cov3 (Convolution1D)             (None, 54, 80)        25680       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 54, 80)        0           cov3[0][0]                       
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 54, 80)        0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
cov4 (Convolution1D)             (None, 51, 80)        25680       dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 51, 80)        0           cov4[0][0]                       
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 51, 80)        0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
cov5 (Convolution1D)             (None, 48, 80)        25680       dropout_4[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 48, 80)        0           cov5[0][0]                       
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 48, 80)        0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 3840)          0           dropout_5[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 100)           384100      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_6 (LeakyReLU)          (None, 100)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_6 (Dropout)              (None, 100)           0           leakyrelu_6[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             101         dropout_6[0][0]                  
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 1)             0           dense_2[0][0]                    
====================================================================================================
Total params: 475481
____________________________________________________________________________________________________
**************vadiation results on validation dataset************
  32/3919 [..............................] - ETA: 0s  96/3919 [..............................] - ETA: 0s 192/3919 [>.............................] - ETA: 0s 288/3919 [=>............................] - ETA: 0s 384/3919 [=>............................] - ETA: 0s 480/3919 [==>...........................] - ETA: 0s 576/3919 [===>..........................] - ETA: 0s 672/3919 [====>.........................] - ETA: 0s 768/3919 [====>.........................] - ETA: 0s 864/3919 [=====>........................] - ETA: 0s 960/3919 [======>.......................] - ETA: 0s1056/3919 [=======>......................] - ETA: 0s1152/3919 [=======>......................] - ETA: 0s1248/3919 [========>.....................] - ETA: 0s1344/3919 [=========>....................] - ETA: 0s1440/3919 [==========>...................] - ETA: 0s1536/3919 [==========>...................] - ETA: 0s1632/3919 [===========>..................] - ETA: 0s1728/3919 [============>.................] - ETA: 0s1824/3919 [============>.................] - ETA: 0s1920/3919 [=============>................] - ETA: 0s2016/3919 [==============>...............] - ETA: 0s2112/3919 [===============>..............] - ETA: 0s2208/3919 [===============>..............] - ETA: 0s2304/3919 [================>.............] - ETA: 0s2432/3919 [=================>............] - ETA: 0s2560/3919 [==================>...........] - ETA: 0s2688/3919 [===================>..........] - ETA: 0s2816/3919 [====================>.........] - ETA: 0s2944/3919 [=====================>........] - ETA: 0s3072/3919 [======================>.......] - ETA: 0s3200/3919 [=======================>......] - ETA: 0s3296/3919 [========================>.....] - ETA: 0s3424/3919 [=========================>....] - ETA: 0s3552/3919 [==========================>...] - ETA: 0s3680/3919 [===========================>..] - ETA: 0s3808/3919 [============================>.] - ETA: 0s3919/3919 [==============================] - 0s     
[0.31963579152487587, 0.87854044403644138]
  32/3919 [..............................] - ETA: 0s 160/3919 [>.............................] - ETA: 0s 288/3919 [=>............................] - ETA: 0s 416/3919 [==>...........................] - ETA: 0s 544/3919 [===>..........................] - ETA: 0s 672/3919 [====>.........................] - ETA: 0s 800/3919 [=====>........................] - ETA: 0s 928/3919 [======>.......................] - ETA: 0s1056/3919 [=======>......................] - ETA: 0s1184/3919 [========>.....................] - ETA: 0s1312/3919 [=========>....................] - ETA: 0s1440/3919 [==========>...................] - ETA: 0s1568/3919 [===========>..................] - ETA: 0s1696/3919 [===========>..................] - ETA: 0s1824/3919 [============>.................] - ETA: 0s1952/3919 [=============>................] - ETA: 0s2080/3919 [==============>...............] - ETA: 0s2208/3919 [===============>..............] - ETA: 0s2336/3919 [================>.............] - ETA: 0s2464/3919 [=================>............] - ETA: 0s2592/3919 [==================>...........] - ETA: 0s2720/3919 [===================>..........] - ETA: 0s2848/3919 [====================>.........] - ETA: 0s2976/3919 [=====================>........] - ETA: 0s3104/3919 [======================>.......] - ETA: 0s3232/3919 [=======================>......] - ETA: 0s3360/3919 [========================>.....] - ETA: 0s3488/3919 [=========================>....] - ETA: 0s3616/3919 [==========================>...] - ETA: 0s3744/3919 [===========================>..] - ETA: 0s3904/3919 [============================>.] - ETA: 0s  32/3919 [..............................] - ETA: 0s 160/3919 [>.............................] - ETA: 0s 288/3919 [=>............................] - ETA: 0s 448/3919 [==>...........................] - ETA: 0s 576/3919 [===>..........................] - ETA: 0s 704/3919 [====>.........................] - ETA: 0s 832/3919 [=====>........................] - ETA: 0s 992/3919 [======>.......................] - ETA: 0s1120/3919 [=======>......................] - ETA: 0s1280/3919 [========>.....................] - ETA: 0s1440/3919 [==========>...................] - ETA: 0s1600/3919 [===========>..................] - ETA: 0s1760/3919 [============>.................] - ETA: 0s1920/3919 [=============>................] - ETA: 0s2080/3919 [==============>...............] - ETA: 0s2240/3919 [================>.............] - ETA: 0s2400/3919 [=================>............] - ETA: 0s2560/3919 [==================>...........] - ETA: 0s2720/3919 [===================>..........] - ETA: 0s2880/3919 [=====================>........] - ETA: 0s3040/3919 [======================>.......] - ETA: 0s3200/3919 [=======================>......] - ETA: 0s3360/3919 [========================>.....] - ETA: 0s3520/3919 [=========================>....] - ETA: 0s3680/3919 [===========================>..] - ETA: 0s3840/3919 [============================>.] - ETA: 0s************************
auc: 0.942620011251
mcc: 0.760595391828
negative ---> precision:0.845365626456, recall:0.926493108729, f1score:0.884072089625, support:1959
positive ---> precision:0.918735891648, recall:0.830612244898, f1score:0.872454448017, support:1960
************************
**************prediction results on test dataset************
  32/3930 [..............................] - ETA: 0s 192/3930 [>.............................] - ETA: 0s 352/3930 [=>............................] - ETA: 0s 512/3930 [==>...........................] - ETA: 0s 672/3930 [====>.........................] - ETA: 0s 832/3930 [=====>........................] - ETA: 0s 992/3930 [======>.......................] - ETA: 0s1152/3930 [=======>......................] - ETA: 0s1312/3930 [=========>....................] - ETA: 0s1472/3930 [==========>...................] - ETA: 0s1632/3930 [===========>..................] - ETA: 0s1792/3930 [============>.................] - ETA: 0s1952/3930 [=============>................] - ETA: 0s2112/3930 [===============>..............] - ETA: 0s2272/3930 [================>.............] - ETA: 0s2432/3930 [=================>............] - ETA: 0s2592/3930 [==================>...........] - ETA: 0s2752/3930 [====================>.........] - ETA: 0s2912/3930 [=====================>........] - ETA: 0s3072/3930 [======================>.......] - ETA: 0s3232/3930 [=======================>......] - ETA: 0s3392/3930 [========================>.....] - ETA: 0s3552/3930 [==========================>...] - ETA: 0s3712/3930 [===========================>..] - ETA: 0s3872/3930 [============================>.] - ETA: 0s[0.35206168564676327, 0.8730279898218829]
  32/3930 [..............................] - ETA: 0s 192/3930 [>.............................] - ETA: 0s 352/3930 [=>............................] - ETA: 0s 512/3930 [==>...........................] - ETA: 0s 672/3930 [====>.........................] - ETA: 0s 832/3930 [=====>........................] - ETA: 0s 992/3930 [======>.......................] - ETA: 0s1152/3930 [=======>......................] - ETA: 0s1312/3930 [=========>....................] - ETA: 0s1472/3930 [==========>...................] - ETA: 0s1632/3930 [===========>..................] - ETA: 0s1792/3930 [============>.................] - ETA: 0s1952/3930 [=============>................] - ETA: 0s2112/3930 [===============>..............] - ETA: 0s2272/3930 [================>.............] - ETA: 0s2432/3930 [=================>............] - ETA: 0s2592/3930 [==================>...........] - ETA: 0s2752/3930 [====================>.........] - ETA: 0s2912/3930 [=====================>........] - ETA: 0s3072/3930 [======================>.......] - ETA: 0s3232/3930 [=======================>......] - ETA: 0s3392/3930 [========================>.....] - ETA: 0s3552/3930 [==========================>...] - ETA: 0s3712/3930 [===========================>..] - ETA: 0s3872/3930 [============================>.] - ETA: 0s  32/3930 [..............................] - ETA: 0s 192/3930 [>.............................] - ETA: 0s 352/3930 [=>............................] - ETA: 0s 512/3930 [==>...........................] - ETA: 0s 672/3930 [====>.........................] - ETA: 0s 832/3930 [=====>........................] - ETA: 0s 992/3930 [======>.......................] - ETA: 0s1152/3930 [=======>......................] - ETA: 0s1312/3930 [=========>....................] - ETA: 0s1472/3930 [==========>...................] - ETA: 0s1632/3930 [===========>..................] - ETA: 0s1792/3930 [============>.................] - ETA: 0s1952/3930 [=============>................] - ETA: 0s2112/3930 [===============>..............] - ETA: 0s2272/3930 [================>.............] - ETA: 0s2432/3930 [=================>............] - ETA: 0s2592/3930 [==================>...........] - ETA: 0s2752/3930 [====================>.........] - ETA: 0s2912/3930 [=====================>........] - ETA: 0s3072/3930 [======================>.......] - ETA: 0s3232/3930 [=======================>......] - ETA: 0s3392/3930 [========================>.....] - ETA: 0s3552/3930 [==========================>...] - ETA: 0s3712/3930 [===========================>..] - ETA: 0s3872/3930 [============================>.] - ETA: 0s************************
auc: 0.93370405343
mcc: 0.75181146839
negative ---> precision:0.832050701675, recall:0.93489318413, f1score:0.880479041916, support:1966
positive ---> precision:0.925624636839, recall:0.811099796334, f1score:0.864586160109, support:1964
************************
